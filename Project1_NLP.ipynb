{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edponce/DoyleInvestigators/blob/master/Project1_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D64o3VubPHvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import urllib.request\n",
        "import urllib.parse\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv7gPdfwPSxq",
        "colab_type": "text"
      },
      "source": [
        "###$\\color{brown}{\\rm Corpus~Selection}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbl0IcL4PQGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CORPUS_URL = {\n",
        "    'The Valley of Fear': \"http://www.gutenberg.org/files/3289/3289.txt\",\n",
        "    'A Study of Scarlet': \"http://www.gutenberg.org/files/244/244.txt\",\n",
        "    'The Sign of the Four': \"http://www.gutenberg.org/files/2097/2097.txt\",\n",
        "    'The Hound of the Baskervilles': \"http://www.gutenberg.org/files/2852/2852.txt\",\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbEAIVRj7lbu",
        "colab_type": "text"
      },
      "source": [
        "###$\\color{brown}{\\rm Read~Web~Page~Content}$\n",
        "Read the corpus from web page to start processing. Use text in ASCII format (no BOMs) and remove Windows-based newlines '\\r'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AIatw6d7gUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corpus_from_url(url):\n",
        "    with urllib.request.urlopen(url) as fd:\n",
        "        return fd.read().decode('ascii')\n",
        "\n",
        "\n",
        "def get_corpus_from_file(file):\n",
        "    with open(file) as fd:\n",
        "        return fd.read()\n",
        "\n",
        "\n",
        "def get_corpus(key):\n",
        "    def validate_url(url):\n",
        "        parsed_url = urllib.parse.urlparse(url)\n",
        "        return all([parsed_url.scheme, parsed_url.netloc, parsed_url.path])\n",
        "\n",
        "    # Check if a filename was provided\n",
        "    if os.path.isfile(key):\n",
        "        return get_corpus_from_file(key)\n",
        "    else:\n",
        "        file = os.path.basename(CORPUS_URL.get(key))\n",
        "        if os.path.isfile(file):\n",
        "            return get_corpus_from_file(file)\n",
        "\n",
        "    # Check if a URL was provided\n",
        "    if validate_url(key):\n",
        "        return get_corpus_from_url(key)\n",
        "    else:\n",
        "        url = CORPUS_URL.get(key)\n",
        "        if validate_url(url):\n",
        "            return get_corpus_from_url(url)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q8QE-jl8q-0",
        "colab_type": "text"
      },
      "source": [
        "###$\\color{brown}{\\rm Split~into~Parts~and~Chapters}$\n",
        "CORE METHODS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFVpoNyQTRp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gutenberg_start_tag(text):\n",
        "    \"\"\"Find Gutenberg's start tag (and producer, if available).\n",
        "\n",
        "    Notes:\n",
        "        * re.match() searches at the beginning of strings, but there are\n",
        "          certain character combinations that are not considered strings,\n",
        "          and thus need to use re.search(), even if it is at the beginning\n",
        "          of line. An example are the asterisks in the Gutenberg START\n",
        "          tag.\n",
        "    \"\"\"\n",
        "    return re.search(\n",
        "        r'\\s*\\r?\\n'  # pre-whitespace\n",
        "        r'\\*{3} '  # 3 asterisks\n",
        "        r'start[^\\r\\n]+'  # tag text\n",
        "        r' \\*{3}'  # 3 asterisks\n",
        "        r'\\r?\\n\\s*'  # post-whitespace\n",
        "        r'(produced by.+\\r?\\n\\s*)?',  # producer line with post-whitespace\n",
        "        text\n",
        "    )\n",
        "\n",
        "\n",
        "def get_gutenberg_end_tag(text):\n",
        "    \"\"\"Find Gutenberg's end tag (and transcriber's notes, if available).\n",
        "\n",
        "    Notes:\n",
        "        * Duplicate/similar Gutenberg end tags.\n",
        "        * Use a newline before transcriber note to prevent matching similar\n",
        "          (but indented) notes at beginning of text.\n",
        "        * Use DOTALL flag to match transcriber's notes across multiple lines.\n",
        "          But be wary that using DOTALL prevents the use of '.+' for other\n",
        "          cases, so use '[^\\r\\n]' instead.\n",
        "    \"\"\"\n",
        "    return re.search(\n",
        "        r'('\n",
        "        r'(\\s*\\r?\\noriginal transcriber.+)?'  # transcriber notes with pre-whitespace\n",
        "        r'\\s*\\r?\\n'  # pre-whitespace\n",
        "        r'end[^\\r\\n]+'  # duplicate/similar tag text\n",
        "        r')?'\n",
        "        r'\\s+'  # pre-whitespace\n",
        "        r'\\*{3} '  # 3 asterisks\n",
        "        r\"end[^\\r\\n]+\"  # tag text\n",
        "        r' \\*{3}'  # 3 asterisks\n",
        "        r'\\r?\\n\\s*',  # post-whitespace\n",
        "        text, flags=re.DOTALL\n",
        "    )\n",
        "\n",
        "\n",
        "def get_gutenberg_part_labels(text):\n",
        "    \"\"\"\n",
        "    Notes:\n",
        "        * We consider the start of the text when the first part/chapter starts.\n",
        "    \"\"\"\n",
        "    return list(re.finditer(\n",
        "        r'\\s*\\r?\\n'  # pre-whitespace\n",
        "        r'('\n",
        "        r'part (\\d|[ivx])+'  # label with Arabic or Roman numbering\n",
        "        r'(-+|\\.)?'  # label-title delimiter\n",
        "        r'.*'  # title\n",
        "        r')'\n",
        "        r'\\r?\\n\\s*',  # post-whitespace\n",
        "        text\n",
        "    ))\n",
        "\n",
        "\n",
        "def get_gutenberg_chapter_labels(text):\n",
        "    \"\"\"\n",
        "    Notes:\n",
        "        * Some text have the chapter tag and title in different lines.\n",
        "    \"\"\"\n",
        "    return list(re.finditer(\n",
        "        r'\\s*'  # pre-whitespace\n",
        "        r'\\r?\\n'  # no indentation\n",
        "        r'('\n",
        "        r'chapter (\\d|[ivx])+'  # label with Arabic or Roman numbering\n",
        "        r'(-+|\\.)?'  # label-title delimiter\n",
        "        r'(\\s{2})?'  # whitespace for titles two line apart\n",
        "        r'.*'  # title\n",
        "        r')'\n",
        "        r'\\r?\\n\\s*',  # post-whitespace\n",
        "        text\n",
        "    ))\n",
        "\n",
        "\n",
        "def get_gutenberg_epilogue_label(text):\n",
        "    return re.search(\n",
        "        r'\\s*\\r?\\n'  # pre-whitespace\n",
        "        r'epilogue'  # tag text\n",
        "        r'\\r?\\n\\s*',  # post-whitespace\n",
        "        text\n",
        "    )\n",
        "\n",
        "\n",
        "def get_toc(text):\n",
        "    \"\"\"Table of contents.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_prologue(text):\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_epilogue(text):\n",
        "    epilogue_label = get_gutenberg_epilogue_label(text)\n",
        "    if epilogue_label:\n",
        "        etag = get_gutenberg_end_tag(text)\n",
        "        return epilogue_label.end(), etag.start()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoh4upkIhTf_",
        "colab_type": "text"
      },
      "source": [
        "Utility methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOlmReiDeYdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_part(text, part_num, *, part_labels=None):\n",
        "    \"\"\"Get span of a selected part.\n",
        "\n",
        "    Args:\n",
        "        part_num (int): Natural number of parts [1-N]\n",
        "    \"\"\"\n",
        "    # NOTE: This can be a required parameter, but simplifies invocation of this function.\n",
        "    if part_labels is None:\n",
        "        part_labels = get_gutenberg_part_labels(text)\n",
        "    if part_num < 1 or part_num > len(part_labels):\n",
        "        raise Exception('part number out-of-range')\n",
        "\n",
        "    start = part_labels[part_num - 1].end()\n",
        "    if part_num == len(part_labels):\n",
        "        epilogue_label = get_gutenberg_epilogue_label(text)\n",
        "        end = (\n",
        "            epilogue_label.start()\n",
        "            if epilogue_label\n",
        "            else get_gutenberg_end_tag(text).start()\n",
        "        )\n",
        "    else:\n",
        "        end = part_labels[part_num].start()\n",
        "    return start, end\n",
        "\n",
        "\n",
        "def get_parts(text):\n",
        "    part_labels = get_gutenberg_part_labels(text)\n",
        "    for part_num in range(1, len(part_labels) + 1):\n",
        "        yield get_part(text, part_num, part_labels=part_labels)\n",
        "\n",
        "\n",
        "def get_chapter(text, chapter_num, part_num=None, *, chapter_labels=None, part_labels=None):\n",
        "    \"\"\"Get span of chapter.\n",
        "\n",
        "    Args:\n",
        "        chapter_num (int): Natural number of chapters [1-N]\n",
        "\n",
        "        part_num (int): Natural number of parts [1-N]\n",
        "    \"\"\"\n",
        "    # NOTE: This can be a required value. This simplifies invocation of this function.\n",
        "    if chapter_labels is None:\n",
        "        chapter_labels = get_gutenberg_chapter_labels(text)\n",
        "    if chapter_num < 1 or chapter_num > len(chapter_labels):\n",
        "        raise Exception('chapter number out-of-range')\n",
        "\n",
        "    if part_labels is None:\n",
        "        part_labels = get_gutenberg_part_labels(text)\n",
        "    if part_num is not None and (part_num < 1 or part_num > len(part_labels)):\n",
        "        raise Exception('part number out-of-range')\n",
        "\n",
        "    if part_num is not None:\n",
        "        # Filter chapters not found in selected part\n",
        "        part = get_part(text, part_num, part_labels=part_labels)\n",
        "        chapter_labels = [\n",
        "            label\n",
        "            for label in chapter_labels\n",
        "            if label.end() >= part[0] and label.end() <= part[1]\n",
        "        ]\n",
        "\n",
        "    # Last chapter\n",
        "    start = chapter_labels[chapter_num - 1].end()\n",
        "    if chapter_num == len(chapter_labels):\n",
        "        # Last chapter of last part\n",
        "        if part_num is None or part_num == len(part_labels):\n",
        "            epilogue_label = get_gutenberg_epilogue_label(text)\n",
        "            end = (\n",
        "                epilogue_label.start()\n",
        "                if epilogue_label\n",
        "                else get_gutenberg_end_tag(text).start()\n",
        "            )\n",
        "        # Last chapter of intermediate part\n",
        "        elif part_num is None:\n",
        "            end = chapter_labels[chapter_num].start()\n",
        "        else:\n",
        "            end = part[1]\n",
        "    else:\n",
        "        end = chapter_labels[chapter_num].start()\n",
        "    return start, end\n",
        "\n",
        "\n",
        "def get_chapters(text, part_num=None):\n",
        "    \"\"\"Get iterator of chapter spans.\n",
        "\n",
        "    Args:\n",
        "        part_num (int): Natural number of parts [1-N]\n",
        "    \"\"\"\n",
        "    chapter_labels = get_gutenberg_chapter_labels(text)\n",
        "    part_labels = get_gutenberg_part_labels(text)\n",
        "\n",
        "    # Text has parts\n",
        "    if part_labels:\n",
        "        if part_num is not None and (part_num < 1 or part_num > len(part_labels)):\n",
        "            raise Exception('part number out-of-range')\n",
        "\n",
        "        for part_num in (\n",
        "            range(1, len(part_labels) + 1)\n",
        "            if part_num is None\n",
        "            else range(part_num, part_num + 1)\n",
        "        ):\n",
        "            # Filter chapters not found in current part\n",
        "            part = get_part(text, part_num, part_labels=part_labels)\n",
        "            _chapter_labels = [\n",
        "                label\n",
        "                for label in chapter_labels\n",
        "                if label.end() >= part[0] and label.end() <= part[1]\n",
        "            ]\n",
        "            for chapter_num in range(1, len(_chapter_labels) + 1):\n",
        "                yield get_chapter(text, chapter_num, part_num, chapter_labels=_chapter_labels, part_labels=part_labels)\n",
        "\n",
        "    # Text does not has parts\n",
        "    else:\n",
        "        if part_num is not None:\n",
        "            print('Warning: no parts found, so part-related parameters are ignored')\n",
        "        for chapter_num in range(1, len(chapter_labels) + 1):\n",
        "            yield get_chapter(text, chapter_num, chapter_labels=chapter_labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_A4do2w4m1u",
        "colab_type": "text"
      },
      "source": [
        "Get paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUievT-74mIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[\\d|\"|\\w](.+\\n)+\\n*(\"(.+\\n)+\\n+)* --> get paragraphs followed by paragraphs that starts with >>\"<<\n",
        "#[\\d|\"|\\w](.+\\n)+(.+:)\\n+(.+\\n?)+  --> get paragraphs that has >>:<< followed by one more paragraph\n",
        "#[\\d|\"|\\w](.+\\n)+(.+:)\\n+(.+\\n?)+|[\\d|\"|\\w](.+\\n)+\\n*(\"(.+\\n)+\\n+)* --> union of the previous two\n",
        "\n",
        "def get_paragraphs(text, span):\n",
        "    def _get_paragraphs(text):\n",
        "        return [\n",
        "            match.span()\n",
        "            for match in re.finditer(\n",
        "              r'('\n",
        "                r'([^\\r\\n]+\\r?\\n)+'  # (regular text with newline)+\n",
        "                r'('\n",
        "                r'(\\r?\\n)+'  # (newline)+\n",
        "                r'[^a-zA-Z]'  # non-alpha character: quote, number, etc.\n",
        "                r')?'  # handles case of multiple newlines but still same paragraph\n",
        "                r')+',  # (full regex)+\n",
        "                text\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    # Get paragraphs from text\n",
        "    # Add base offset to paragraphs' spans\n",
        "    paragraphs = [\n",
        "        (par[0]+span[0], par[1]+span[0])\n",
        "        for par in _get_paragraphs(text[span[0]:span[1]])\n",
        "    ]\n",
        "\n",
        "    # Extend last paragraph to end of text\n",
        "    if paragraphs:\n",
        "        paragraphs[-1] = paragraphs[-1][0], span[1]\n",
        "    else:\n",
        "        paragraphs = [span]\n",
        "\n",
        "    return paragraphs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA8jVevEiDo0",
        "colab_type": "text"
      },
      "source": [
        "###$\\color{brown}{\\rm Preprocess~Corpus}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAqfGF9pTXsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_parts_chapters():\n",
        "    for title in CORPUS_URL:\n",
        "        print(title)\n",
        "        print('-' * len(title))\n",
        "\n",
        "        corpus = get_corpus(title)\n",
        "        _corpus = corpus.lower()\n",
        "\n",
        "        for span in get_parts(_corpus):\n",
        "            print(span)\n",
        "            # print(corpus[span[0]:span[0]+100])\n",
        "            # print('...')\n",
        "            # print(corpus[span[1]-100:span[1]])\n",
        "\n",
        "        print()\n",
        "\n",
        "        for span in get_chapters(_corpus):\n",
        "            print(span)\n",
        "            # print(corpus[span[0]:span[0]+100])\n",
        "            # print('...')\n",
        "            # print(corpus[span[1]-100:span[1]])\n",
        "\n",
        "        print()\n",
        "        print()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y63vLBPBTvFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3e0d257-0ee6-46eb-a350-1ad422609775"
      },
      "source": [
        "print_parts_chapters()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Valley of Fear\n",
            "------------------\n",
            "(771, 153679)\n",
            "(153721, 315571)\n",
            "\n",
            "(801, 17931)\n",
            "(17986, 33434)\n",
            "(33487, 52429)\n",
            "(52466, 73638)\n",
            "(73690, 96082)\n",
            "(96126, 121931)\n",
            "(121972, 153679)\n",
            "(153747, 170681)\n",
            "(170724, 200879)\n",
            "(200927, 231808)\n",
            "(231855, 251712)\n",
            "(251757, 277395)\n",
            "(277430, 295740)\n",
            "(295798, 315571)\n",
            "\n",
            "\n",
            "A Study of Scarlet\n",
            "------------------\n",
            "(1856, 125158)\n",
            "(125217, 245813)\n",
            "\n",
            "(2014, 17680)\n",
            "(17733, 38387)\n",
            "(38448, 60325)\n",
            "(60381, 74188)\n",
            "(74250, 88120)\n",
            "(88184, 106475)\n",
            "(106526, 125158)\n",
            "(125260, 146010)\n",
            "(146057, 160651)\n",
            "(160716, 171025)\n",
            "(171071, 190062)\n",
            "(190109, 210109)\n",
            "(210193, 233926)\n",
            "(233970, 245813)\n",
            "\n",
            "\n",
            "The Sign of the Four\n",
            "--------------------\n",
            "\n",
            "(759, 17754)\n",
            "(17776, 28385)\n",
            "(28408, 38358)\n",
            "(38380, 59609)\n",
            "(59630, 74129)\n",
            "(74151, 91615)\n",
            "(91638, 115314)\n",
            "(115338, 134278)\n",
            "(134300, 154062)\n",
            "(154083, 172511)\n",
            "(172533, 184243)\n",
            "(184266, 238563)\n",
            "\n",
            "\n",
            "The Hound of the Baskervilles\n",
            "-----------------------------\n",
            "\n",
            "(745, 13659)\n",
            "(13717, 37232)\n",
            "(37272, 53593)\n",
            "(53643, 76314)\n",
            "(76363, 95354)\n",
            "(95399, 114729)\n",
            "(114790, 141797)\n",
            "(141852, 156896)\n",
            "(156978, 192084)\n",
            "(192150, 211533)\n",
            "(211581, 236402)\n",
            "(236449, 259420)\n",
            "(259465, 281775)\n",
            "(281834, 304462)\n",
            "(304507, 327212)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0w0C-LK2KG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "ae0ea0e3-8555-47d9-e041-959344e89bfb"
      },
      "source": [
        "corpus = get_corpus('The Valley of Fear')\n",
        "_corpus = corpus.lower()\n",
        "\n",
        "for chapter_num, chapter_span in enumerate(get_chapters(_corpus), start=1):\n",
        "    print(f'Chapter {chapter_num} - {chapter_span}')\n",
        "    print('=' * 40)\n",
        "    for par in get_paragraphs(corpus, chapter_span):\n",
        "        print(par)\n",
        "        #print(corpus[par[0]:par[1]])\n",
        "        #print('-' * 40)\n",
        "    break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chapter 1 - (801, 17931)\n",
            "========================================\n",
            "(801, 896)\n",
            "(898, 1099)\n",
            "(1101, 1748)\n",
            "(1750, 4841)\n",
            "(4843, 6300)\n",
            "(6302, 7328)\n",
            "(7330, 8695)\n",
            "(8697, 13036)\n",
            "(13038, 14372)\n",
            "(14374, 15155)\n",
            "(15157, 15451)\n",
            "(15453, 16042)\n",
            "(16044, 17305)\n",
            "(17307, 17756)\n",
            "(17758, 17931)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m2njKTnSM6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "164a4d45-868f-4165-9e5c-66544339adc5"
      },
      "source": [
        "list(get_chapters(_corpus))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(801, 17931),\n",
              " (17986, 33434),\n",
              " (33487, 52429),\n",
              " (52466, 73638),\n",
              " (73690, 96082),\n",
              " (96126, 121931),\n",
              " (121972, 153679),\n",
              " (153747, 170681),\n",
              " (170724, 200879),\n",
              " (200927, 231808),\n",
              " (231855, 251712),\n",
              " (251757, 277395),\n",
              " (277430, 295740),\n",
              " (295798, 315571)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}