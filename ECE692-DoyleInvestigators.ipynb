{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Project1_NLP.ipynb","provenance":[{"file_id":"https://github.com/edponce/DoyleInvestigators/blob/master/Project1_NLP.ipynb","timestamp":1600920844860}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Hr2wdHfSTKj4","colab_type":"text"},"source":["###$\\color{brown}{\\rm Team Members}$\n","## Fabian Fallas\n","## Maofeng Tang\n","## Chris Gropp\n","## Eduardo Ponce"]},{"cell_type":"markdown","metadata":{"id":"bv7gPdfwPSxq","colab_type":"text"},"source":["###$\\color{brown}{\\rm Imports}$"]},{"cell_type":"code","metadata":{"id":"D64o3VubPHvS","colab_type":"code","colab":{}},"source":["import os\n","import re\n","import copy\n","import pprint\n","import itertools\n","import collections\n","import urllib.request\n","import urllib.parse\n","import numpy as np\n","import seaborn as sns  # 0.10.1 (0.11 fails in barplot due to API change)\n","import pandas\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T-XOfdD4g5lO"},"source":["###$\\color{brown}{\\rm Corpus~Selection}$"]},{"cell_type":"code","metadata":{"id":"Kbl0IcL4PQGL","colab_type":"code","colab":{}},"source":["CORPUS_URL = {\n","    'The Valley of Fear': \"http://www.gutenberg.org/files/3289/3289.txt\",\n","    'A Study in Scarlet': \"http://www.gutenberg.org/files/244/244.txt\",\n","    'The Sign of the Four': \"http://www.gutenberg.org/files/2097/2097.txt\",\n","    'The Hound of the Baskervilles': \"http://www.gutenberg.org/files/2852/2852.txt\",\n","    # NOTE: This file is a compilation of adventures where \"The Boscombe Valley Mystery\" is Adventure 4\n","    'The Boscombe Valley Mystery': 'https://www.gutenberg.org/files/1661/1661.txt',\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jum0u8PPILo6","colab_type":"text"},"source":["###$\\color{brown}{\\rm Characters~and~Aliases}$\n","* Names and aliases are case-sensitive\n","* Underscores are used to prevent token splits when creating variant forms"]},{"cell_type":"code","metadata":{"id":"MLF6Xu24II7K","colab_type":"code","colab":{}},"source":["CHARACTERS_NAMES = {\n","    'The Valley of Fear': {\n","        'main': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['John Douglas', 'Birdy Edwards', 'Mr._Douglas', 'Steve Wilson', 'Jack McMurdo'],\n","            ['McGinty', 'Boss', 'Bodymaster'],\n","            ['Alec MacDonald', 'inspector', 'Inspector', 'Mr._Mac', 'Mac'],\n","            ['White Mason', 'police_officer'],\n","            ['Mrs._Douglas'],\n","            ['Cecil James Barker'],\n","            ['Ettie Shafter'],\n","            ['Fred Porlock'],\n","            ['Professor_Moriarty', 'professor'],\n","            ['Sergeant Wilson'],\n","            ['Ted Baldwin', 'Teddy Baldwin', 'Mr._Baldwin'],\n","            ['Captain Marvin'],\n","        ],\n","        'detectives': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Alec MacDonald', 'inspector', 'Inspector', 'Mr._Mac', 'Mac'],\n","            ['White Mason', 'police_officer'],\n","        ],\n","        'perpetrators': [\n","            ['Professor Moriarty', 'professor'],\n","            ['Ted Baldwin', 'Teddy Baldwin', 'Mr._Baldwin'],\n","        ],\n","        'suspects': [\n","            ['Mrs. Douglas'],\n","            ['Cecil James Barker'],\n","        ],\n","    },\n","    'A Study in Scarlet': {\n","        'main': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['John', 'John_Ferrier'],\n","            ['Lucy'],\n","            ['Enoch Drebber'],\n","            ['Joseph Stangerson'],\n","            ['Lestrade'],\n","            ['Gregson'],\n","            ['Jefferson Hope', 'cabman'],\n","            ['Brigham Young'],\n","            ['Madame_Charpentier', 'Madame', 'Mrs._Charpentier'],\n","            ['Arthur_Charpentier', 'Arthur'],\n","        ],\n","        'detectives': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Gregson'],\n","            ['Lestrade'],\n","        ],\n","        'perpetrators': [\n","            ['Jefferson Hope', 'cabman'],  # Part 1\n","            # ['Enoch Drebber'],  # Part 2\n","            # ['Joseph Stangerson'],  # Part 2\n","        ],\n","        'suspects': [\n","            ['Enoch Drebber'],  # Part 1\n","            ['Joseph Stangerson'],  # Part 1\n","            ['Madame_Charpentier', 'Madame', 'Mrs._Charpentier'],  # Part 1\n","            ['Arthur_Charpentier', 'Arthur'],  # Part 1\n","        ],\n","    },\n","    'The Sign of the Four': {\n","        'main': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Mary_Morstan', 'Miss_Morstan'],\n","            ['Arthur_Morstan', 'Captain_Morstan'],\n","            ['Major_Sholto', 'Major', 'major'],\n","            ['Thaddeus_Sholto', 'Thaddeus'],\n","            ['Bartholomew_Sholto', 'Bartholomew'],\n","            ['Jonathan Small'],\n","            ['Tonga'],\n","        ],\n","        'detectives': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","        ],\n","        'perpetrators': [\n","            ['Jonathan Small'],\n","            ['Tonga'],\n","        ],\n","        'suspects': [\n","            ['Major_Sholto', 'Major', 'major'],\n","            ['Thaddeus_Sholto', 'Thaddeus'],\n","        ],\n","    },\n","    'The Hound of the Baskervilles': {\n","        'main': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['James Mortimer', 'doctor', 'Doctor'],\n","            ['Charles_Baskerville', 'Sir_Charles'],\n","            ['Henry Baskerville', 'Sir_Henry'],\n","            ['Jack', 'Stapleton'],\n","            ['Miss_Stapleton', 'Beryl'],\n","            ['Barrymore', 'butler'],\n","            ['Selden'],\n","            ['Laura Lyons'],\n","        ],\n","        'detectives': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Lestrade'],\n","        ],\n","        'perpetrators': [\n","            ['Jack', 'Stapleton'],\n","        ],\n","        'suspects': [\n","            ['Barrymore', 'butler'],\n","            ['Laura Lyons'],\n","        ],\n","    },\n","    'The Boscombe Valley Mystery': {\n","        'main': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Lestrade'],\n","            ['James McCarthy'],\n","            ['John_Turner', 'Mr._Turner', 'Turner'],\n","            ['Alice', 'Miss_Turner'],\n","        ],\n","        'detectives': [\n","            ['Sherlock Holmes'],\n","            ['Watson'],\n","            ['Lestrade'],\n","        ],\n","        'perpetrators': [\n","            ['John_Turner', 'Mr._Turner', 'Turner'],\n","        ],\n","        'suspects': [\n","            ['James McCarthy'],\n","        ],\n","    },\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbEAIVRj7lbu","colab_type":"text"},"source":["###$\\color{brown}{\\rm Load~Corpus}$\n","Read a corpus from web page or file to start processing."]},{"cell_type":"code","metadata":{"id":"3AIatw6d7gUZ","colab_type":"code","colab":{}},"source":["def get_corpus_from_url(url):\n","    with urllib.request.urlopen(url) as fd:\n","        text = fd.read()\n","        try:\n","            return text.decode('utf-8')\n","        except UnicodeDecodeError:\n","            return text.decode('iso-8859-1')\n","\n","\n","def get_corpus_from_file(file):\n","    with open(file) as fd:\n","        return fd.read()\n","\n","\n","def get_corpus(key):\n","    def validate_url(url):\n","        parsed_url = urllib.parse.urlparse(url)\n","        return all([parsed_url.scheme, parsed_url.netloc, parsed_url.path])\n","\n","    # Check if a filename was provided\n","    if os.path.isfile(key):\n","        return get_corpus_from_file(key)\n","    else:\n","        if key in CORPUS_URL:\n","            file = os.path.basename(CORPUS_URL[key])\n","            if os.path.isfile(file):\n","                return get_corpus_from_file(file)\n","\n","    # Check if a URL was provided\n","    if validate_url(key):\n","        return get_corpus_from_url(key)\n","    else:\n","        if key in CORPUS_URL:\n","            url = CORPUS_URL[key]\n","            if validate_url(url):\n","                return get_corpus_from_url(url)\n","\n","    raise Exception(f\"corpus '{key}' not found\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3q8QE-jl8q-0","colab_type":"text"},"source":["###$\\color{brown}{\\rm Headings~Detection~(Regex)}$\n","Functions to get spans of headings:\n","* Gutenberg tags\n","* Named headings - parts, chapters, adventures\n","* Numbered headings\n","* Epilogue"]},{"cell_type":"code","metadata":{"id":"qFVpoNyQTRp0","colab_type":"code","colab":{}},"source":["def get_newline_index(text):\n","    \"\"\"Find the index of the first newline in the text.\n","    This is used to skip/correct one newline at beginning of headings.\n","    \"\"\"\n","    match = re.match(r'[ \\t\\r]*\\n', text)\n","    return match.end() if match else 0\n","\n","\n","def get_gutenberg_start_heading(text, span=None):\n","    \"\"\"Find Gutenberg's start tag (and producer, if available).\n","\n","    Notes:\n","        * re.match() searches at the beginning of strings, but there are\n","          certain character combinations that are not considered strings,\n","          and thus need to use re.search(), even if it is at the beginning\n","          of line. An example are the asterisks in the Gutenberg START\n","          tag.\n","    \"\"\"\n","    if not span:\n","        span = (0, len(text))\n","\n","    match = re.search(\n","        r'(^\\s*|(\\s*\\n){2,})'  # pre-whitespace, no indentation\n","        r'\\*{3}\\s*'  # 3 asterisks\n","        r'start[^\\r\\n]+'  # tag text\n","        r'\\s*\\*{3}'  # 3 asterisks\n","        r'(\\s*\\nproduced by.+)?'  # producer line\n","        r'(\\s*\\n){2,}',  # post-whitespace\n","        text[span[0]:span[1]],\n","    )\n","\n","    if match:\n","        span = match.span()\n","        offs = get_newline_index(text[span[0]:span[1]])\n","        return span[0] + offs, span[1]\n","\n","\n","def get_gutenberg_end_heading(text, span=None):\n","    \"\"\"Find Gutenberg's end tag (and transcriber's notes, if available).\n","\n","    Notes:\n","        * Duplicate/similar Gutenberg end tags.\n","        * Use a newline before transcriber note to prevent matching similar\n","          (but indented) notes at beginning of text.\n","        * Use DOTALL flag to match transcriber's notes across multiple lines.\n","          But be wary that using DOTALL prevents the use of '.+' for other\n","          cases, so use '[^\\r\\n]' instead.\n","    \"\"\"\n","    if not span:\n","        span = (0, len(text))\n","\n","    match = re.search(\n","        r'('\n","        r'(\\s*\\n){2,}'  # pre-whitespace, no indentation\n","        r'(original transcriber.+\\s*\\n)?'  # transcriber notes\n","        r'end[^\\r\\n]+'  # duplicate/similar tag text\n","        r')?'\n","        r'\\s*\\n'  # pre-whitespace, no indentation\n","        r'\\*{3}\\s*'  # 3 asterisks\n","        r\"end[^\\r\\n]+\"  # tag text\n","        r'\\s*\\*{3}'  # 3 asterisks\n","        r'(\\s*\\n){2,}',  # post-whitespace\n","        text[span[0]:span[1]],\n","        flags=re.DOTALL,\n","    )\n","\n","    if match:\n","        span = match.span()\n","        offs = get_newline_index(text[span[0]:span[1]])\n","        return span[0] + offs, span[1]\n","\n","\n","def get_named_headings(text, name, span=None):\n","    \"\"\"Find named headings with title.\"\"\"\n","    if not span:\n","        span = (0, len(text))\n","\n","    spans = [\n","        (match.start() + span[0], match.end() + span[0])\n","        for match in re.finditer(\n","            r'(^(\\s*)|(\\s*\\n){2,})'  # pre-whitespace, no indentation\n","            r'('\n","            fr'{name}[ \\t]+(\\d+|[ivxlcd]+)'  # label with Arabic/Roman number\n","            r'(-+|\\.)?'  # label-title delimiter\n","            r'((\\s*\\n){2})?'  # whitespace for titles two line apart\n","            r'.*(\\r?\\n.*)?'  # title (muti-line support)\n","            r'|'  # cases: name # \\s* label, # name/label\n","            r'(\\d+|[ivxlcd]+)'  # label with Arabic or Roman numbering\n","            r'(-+|\\.)?'  # label-title delimiter\n","            fr'[ \\t]+.*{name}.*'  # label with name\n","            r')'\n","            r'(\\s*\\n){2,}',  # post-whitespace\n","            text[span[0]:span[1]],\n","        )\n","    ]\n","\n","    _spans = []\n","    for _span in spans:\n","        offs = get_newline_index(text[_span[0]:_span[1]])\n","        _spans.append((_span[0] + offs, _span[1]))\n","    return _spans\n","\n","\n","def get_numbered_headings(text, span=None):\n","    \"\"\"Find numbered headings with no title.\"\"\"\n","    if not span:\n","        span = (0, len(text))\n","\n","    spans = [\n","        (match.start() + span[0], match.end() + span[0])\n","        for match in re.finditer(\n","            r'(^\\s*|(\\s*\\n){2,})'  # pre-whitespace, no indentation\n","            fr'(\\d+|[ivxlcd]+)'  # label with Arabic or Roman numbering\n","            r'(-+|\\.)'  # label-title delimiter\n","            r'(\\s*\\n){2,}',  # post-whitespace\n","            text[span[0]:span[1]]\n","        )\n","    ]\n","\n","    _spans = []\n","    for _span in spans:\n","        offs = get_newline_index(text[_span[0]:_span[1]])\n","        _spans.append((_span[0] + offs, _span[1]))\n","    return _spans\n","\n","\n","def get_epilogue_heading(text, span=None):\n","    if not span:\n","        span = (0, len(text))\n","\n","    match = re.search(\n","        r'(^\\s*|(\\s*\\n){2,})'  # pre-whitespace, no indentation\n","        r'epilogue'  # tag text\n","        r'(\\s*\\n){2,}',  # post-whitespace\n","        text[span[0]:span[1]]\n","    )\n","\n","    if match:\n","        span = match.span()\n","        offs = get_newline_index(text[span[0]:span[1]])\n","        return span[0] + offs, span[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yoh4upkIhTf_","colab_type":"text"},"source":["###$\\color{brown}{\\rm Regions~of~Interest~(ROI)}$\n","Functions to get spans of text between headings."]},{"cell_type":"code","metadata":{"id":"PH5HWEjvKShk","colab_type":"code","colab":{}},"source":["def get_headings_map(\n","    text,\n","    headings=['part', 'chapter', 'adventure', 'epilogue', 'numbered'],\n","):\n","    \"\"\"Create a list of all heading spans, guarantees at least one set\n","    of bounding spans.\n","\n","    Args:\n","        headings (str, List[str]): Heading names to search for.\n","    \"\"\"\n","    if not isinstance(headings, (list, tuple, set)):\n","        _headings = [headings]\n","    else:\n","        _headings = copy.deepcopy(headings)\n","\n","    headings_map = {}\n","    _headings_map = {}\n","\n","    # Always available heading, all text\n","    text_heading = '_text_'\n","\n","    # Ensure there is always a begin \"span\"\n","    start_span = get_gutenberg_start_heading(text)\n","    if not start_span:\n","        start_span = 0, 0\n","\n","    # Ensure there is always an end \"span\"\n","    end_span = get_gutenberg_end_heading(text)\n","    if not end_span:\n","        end_span = len(text), len(text)\n","    headings_map[text_heading] = [start_span, end_span]\n","    if text_heading in _headings:\n","        _headings.remove(text_heading)\n","\n","    # Optional\n","    span = get_epilogue_heading(text)\n","    if span:\n","        heading = 'epilogue'\n","        _headings_map[heading] = [span, headings_map[text_heading][1]]\n","        if heading in _headings:\n","            headings_map[heading] = _headings_map[heading]\n","            _headings.remove(heading)\n","\n","    # Optional\n","    spans = get_numbered_headings(text)\n","    if spans:\n","        heading = 'numbered'\n","        _headings_map[heading] = [*spans, headings_map[text_heading][1]]\n","        if heading in _headings:\n","            headings_map[heading] = _headings_map[heading]\n","            _headings.remove(heading)\n","\n","    # Optional\n","    for heading in _headings:\n","        spans = get_named_headings(text, heading)\n","        if spans:\n","            headings_map[heading] = spans\n","            if 'epilogue' in _headings_map:\n","                headings_map[heading].append(_headings_map['epilogue'][0])\n","            else:\n","                headings_map[heading].append(headings_map[text_heading][1])\n","    return headings_map\n","\n","\n","def select_rois_spans(spans, n=None):\n","    if n is None:\n","        _spans = [\n","            (spans[i][1], spans[i + 1][0])\n","            for i in range(len(spans) - 1)\n","        ]\n","    else:\n","        _spans = [\n","            (spans[i - 1][1], spans[i][0])\n","            for i in ([n] if isinstance(n, int) else n)\n","            if i >= 1 and i < (len(spans))\n","        ]\n","    return _spans\n","\n","\n","def remove_embedded_spans(spans):\n","    non_embedded_spans = copy.deepcopy(spans)\n","    for i in range(len(spans)):\n","        span = spans[i]\n","        for j in range(i + 1, len(spans)):\n","            _span = spans[j]\n","            if span[0] >= _span[0] and span[1] <= _span[1]:\n","                non_embedded_spans.remove(span)\n","                break\n","            elif span[1] > _span[1]:\n","                break\n","    non_embedded_spans.sort()\n","    return non_embedded_spans\n","\n","\n","def get_nonoverlapped_spans(spans, *, join=True):\n","    \"\"\"Remove fully embedded spans and join overlapped spans.\"\"\"\n","    non_embedded_spans = remove_embedded_spans(spans)\n","    non_embedded_spans = remove_embedded_spans(non_embedded_spans[::-1])\n","    if not join:\n","        return non_embedded_spans\n","\n","    joined_spans = []\n","    for span in non_embedded_spans:\n","        for _span in non_embedded_spans:\n","            if span != _span:\n","                joined_span = None\n","                if span[0] >= _span[0] and span[0] <= _span[1]:\n","                    joined_span = (_span[0], span[1])\n","                elif span[1] >= _span[0] and span[1] <= _span[1]:\n","                    joined_span = (span[0], _span[1])\n","                if joined_span:\n","                    if joined_span not in joined_spans:\n","                        joined_spans.append(joined_span)\n","                    break\n","        else:\n","            joined_spans.append(span)\n","\n","    nonoverlap_spans = sorted(joined_spans)\n","\n","    # Recurse until condition is satisfied\n","    if nonoverlap_spans == spans:\n","        return nonoverlap_spans\n","    return get_nonoverlapped_spans(nonoverlap_spans)\n","\n","\n","def contains_span(spans, span):\n","    \"\"\"Validate if a span is contained in a collection of spans.\"\"\"\n","    for _span in spans:\n","        if span[0] >= _span[0] and span[1] <= _span[1]:\n","            return True\n","    return False\n","\n","\n","def get_rois(text, name=None, *, n=None, headings_map=None):\n","    \"\"\"Get span bounding a ROI.\n","\n","    Args:\n","        name (str): ROI\n","\n","        n (int, Iterable[int]): Number of ROI, [1,N]\n","    \"\"\"\n","    if not headings_map:\n","        headings_map = get_headings_map(text)\n","\n","    # Always available heading, all text\n","    text_heading = '_text_'\n","\n","    rois = []\n","    if not name:\n","        rois = [(\n","            headings_map[text_heading][0][1],\n","            headings_map[text_heading][1][0],\n","        )]\n","    elif name in headings_map:\n","        rois = select_rois_spans(headings_map[name], n)\n","\n","    # If necessary, skip last inner heading\n","    _rois = []\n","    for roi in rois:\n","        value = roi[1]\n","        for spans in headings_map.values():\n","            for span in spans:\n","                if roi[1] > span[0] and roi[1] <= span[1]:\n","                    value = span[0]\n","        _rois.append((roi[0], value))\n","    return _rois\n","\n","\n","\n","def get_roi(text, name, span=None, *, n=None):\n","    if not span:\n","        spans = get_rois(text, name, n=n)\n","    else:\n","        spans = [\n","            (_span[0] + span[0], _span[1] + span[0])\n","            for _span in get_rois(text[span[0]:span[1]], name, n=n)\n","        ]\n","    return spans\n","\n","\n","def get_text_from_span(text, span=None):\n","    if not span:\n","        span = (0, len(text))\n","    elif isinstance(span[0], int):\n","        span = [span]\n","\n","    roi = ''\n","    for _span in span:\n","        roi += text[_span[0]:_span[1]]\n","    return roi\n","\n","\n","def get_text(text, span=None, *, n=None):\n","    return get_rois(text)\n","\n","\n","def get_parts(text, span=None, *, n=None):\n","    return get_roi(text, 'part', span, n=n)\n","\n","\n","def get_chapters(text, span=None, *, n=None):\n","    return get_roi(text, 'chapter', span, n=n)\n","\n","\n","def get_adventures(text, span=None, *, n=None):\n","    return get_roi(text, 'adventure', span, n=n)\n","\n","\n","def get_numbered_sections(text, span=None, *, n=None):\n","    return get_roi(text, 'numbered', span, n=n)\n","\n","\n","def get_epilogue(text, span=None):\n","    return get_roi(text, 'epilogue', span)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vlvxv22kLVR8","colab_type":"text"},"source":["###$\\color{brown}{\\rm Tokenization~(Regex)}$\n","Regexes to get text decomposition:\n","* Paragraphs\n","* Sentences\n","* Tokens"]},{"cell_type":"code","metadata":{"id":"2lFxOxLAKtSP","colab_type":"code","colab":{}},"source":["def tokenize(text, span=None, regex=r'\\w', *, use_remaining=False):\n","    def _get_tokens(text):\n","        return [\n","            match.span()\n","            for match in re.finditer(regex, text)\n","        ]\n","\n","    if not span:\n","        span = (0, len(text))\n","\n","    # Get tokens from text\n","    # Add base offset to tokens' spans\n","    tokens = [\n","        (tok_span[0] + span[0], tok_span[1] + span[0])\n","        for tok_span in _get_tokens(text[span[0]:span[1]])\n","    ]\n","\n","    if use_remaining:\n","        if tokens:\n","            # Extend last token to end of text\n","            tokens[-1] = tokens[-1][0], span[1]\n","        else:\n","            # Consider all text as the token\n","            tokens = [span]\n","\n","    return tokens\n","\n","\n","def select_spans(spans, n=None):\n","    if n is None:\n","        _spans = spans\n","    else:\n","        _spans = [\n","            spans[i - 1]\n","            for i in ([n] if isinstance(n, int) else n)\n","            if i >= 1 and i <= (len(spans))\n","        ]\n","    return _spans\n","\n","\n","def get_paragraphs(text, span=None, *, n=None):\n","    spans = tokenize(\n","        text,\n","        span,\n","        r'('\n","        r'([^\\r\\n]+\\r?\\n)+'  # (regular text with newline)+\n","        r'('\n","        r'(\\r?\\n)+'  # (newline)+\n","        r'[^a-zA-Z]'  # non-alpha character: quote, number, etc.\n","        r')?'  # handles case of multiple newlines but still same paragraph\n","        r')+',  # (full regex)+\n","        use_remaining=True,\n","    )\n","    return select_spans(spans, n)\n","\n","\n","def get_sentences(text, span=None, *, n=None):\n","    spans = tokenize(\n","        text,\n","        span,\n","        r'('\n","        r'([^\\.\\r\\n;M!]+(\\r?\\n)?)+'\n","        r'(.\")?'\n","        r'(M[rR][sS]?\\.\\s)?'\n","        r'M?'\n","        r')+'\n","        r'|'\n","        r'M[rR][sS]?'\n","        r'\\.\\s'\n","        r'([^\\.;M!]+(.\")?(M[rR][sS]?\\.\\s)?(M)?)+',\n","    )\n","    return select_spans(spans, n)\n","\n","\n","def get_tokens(text, span=None, *, n=None):\n","    spans = tokenize(\n","        text,\n","        span,\n","        r'\\w+'  # compound alphanumeric words\n","        r'('\n","        r\"'\\w+\"  # contractions\n","        r'|(-\\w+)+'  # tokens with inlined dashes\n","        r')'\n","        r'|\\w+'  # single alphanumeric words\n","        r'|\\$?-?\\d+(,\\d+)*(\\.\\d+)?',  # numbers, decimals, monetary\n","    )\n","    return select_spans(spans, n)\n","\n","\n","def get_conversations(text, span=None, *, n=None):\n","    spans = tokenize(text, span, r'\"[^\"]+\"')\n","    return select_spans(spans, n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6e_Pyk86Kr0o"},"source":["###$\\color{brown}{\\rm Named~Entity~Recognition~(NER)}$\n","Find names of characters/places."]},{"cell_type":"code","metadata":{"id":"_OZh9n7L5hU8","colab_type":"code","colab":{}},"source":["def abbreviate_entity(entity):\n","    \"\"\"Trim names to fit in plots (F. LastName).\"\"\"\n","    entity_parts = entity.split()\n","    if len(entity_parts) == 1:\n","        abbrv = entity\n","    else:\n","        # F. LastName\n","        abbrv = f'{entity_parts[0][0]}. {entity_parts[-1]}'\n","        # FirstName L.\n","        # abbrv = f'{entity_parts[0]} {entity_parts[-1][0]}.'\n","    return abbrv\n","\n","\n","def get_entity_variants(entity, *, invalids=[]):\n","    \"\"\"Given a string with whitespace, return all combinations.\"\"\"\n","    if '_' in entity:\n","        entity_parts = [entity.replace('_', ' ')]\n","    else:\n","        entity_parts = entity.split()\n","\n","    variants = []\n","    for i in range(len(entity_parts)):\n","        for j in range(i+1, len(entity_parts)+1):\n","            variant = ' '.join(entity_parts[i:j])\n","            if variant not in invalids:\n","                variants.append(variant)\n","    return variants\n","\n","\n","def search_entity(entities, text, span=None, *, invalids=[]):\n","    if not isinstance(entities, (list, tuple, set)):\n","        entities = [entities]\n","\n","    if span is None:\n","        span = (0, len(text))\n","\n","    entities_map = collections.defaultdict(list)\n","    for entity in entities:\n","        entity_variants = get_entity_variants(\n","            entity,\n","            invalids=invalids,\n","        )\n","        entity_map = get_keywords_map(text, span, entity_variants)\n","        if entity_map:\n","            for spans in entity_map.values():\n","                entities_map[entity].extend(spans)\n","\n","    return {entities[0]: get_nonoverlapped_spans(list(itertools.chain.from_iterable(entities_map.values())))}\n","\n","def get_max_frequency_from_nested_map(nested_freq_map):\n","    ymax = 0\n","    for _, freq_map in nested_freq_map.items():\n","        ymax = max(ymax, max(freq_map.values()))\n","    return ymax\n","\n","\n","def get_max_frequency_from_nested2_map(nested2_freq_map):\n","    ymax = 0\n","    for _, xmap in nested2_freq_map.items():\n","        ymax = max(ymax, get_max_frequency_from_nested_map(xmap))\n","    return ymax\n","\n","\n","def ner_story_with_chapters(story, span=None):\n","    story_spans = {}\n","    story_counts = {}\n","    corpus = get_corpus(story)\n","    text = corpus.lower()\n","    for character_type, character_list in CHARACTERS_NAMES[story].items():\n","        story_spans[character_type] = {}\n","        story_counts[character_type] = {}\n","        for n, chp_span in enumerate(get_chapters(text, span), start=1):\n","            story_spans[character_type][n] = {}\n","            story_counts[character_type][n] = {}\n","            for character_names in character_list:\n","                story_spans[character_type][n].update(search_entity(character_names, corpus, chp_span))\n","            story_counts[character_type][n] = convert_spans_to_counts_map(story_spans[character_type][n])\n","    return story_spans, story_counts\n","\n","\n","def ner_story(story, span=None):\n","    story_spans = {}\n","    story_counts = {}\n","    corpus = get_corpus(story)\n","    for character_type, character_list in CHARACTERS_NAMES[story].items():\n","        story_spans[character_type] = {}\n","        story_counts[character_type] = {}\n","        story_spans[character_type][0] = {}\n","        story_counts[character_type][0] = {}\n","        for character_names in character_list:\n","            story_spans[character_type][0].update(search_entity(character_names, corpus, span))\n","            story_counts[character_type][0] = convert_spans_to_counts_map(story_spans[character_type][0])\n","    return story_spans, story_counts\n","\n","\n","def ner_story_with_paragraphs(story, span=None):\n","    story_spans = {}\n","    story_counts = {}\n","    corpus = get_corpus(story)\n","    text = corpus.lower()\n","    for character_type, character_list in CHARACTERS_NAMES[story].items():\n","        story_spans[character_type] = {}\n","        story_counts[character_type] = {}\n","        for n, par_span in enumerate(get_paragraphs(text, span), start=1):\n","            story_spans[character_type][n] = {}\n","            story_counts[character_type][n] = {}\n","            for character_names in character_list:\n","                story_spans[character_type][n].update(search_entity(character_names, corpus, par_span))\n","            story_counts[character_type][n] = convert_spans_to_counts_map(story_spans[character_type][n])\n","    return story_spans, story_counts\n","\n","\n","def plot_ner_counts_story_with_chapters(story, counts, *, show=False):\n","    ylim = (0, get_max_frequency_from_nested2_map(counts))\n","    for character_type in CHARACTERS_NAMES[story].keys():\n","        ns = int(np.ceil(np.sqrt(len(counts[character_type]))))\n","        fig, axes = plt.subplots(ns, ns, constrained_layout=True)\n","        axes = trim_axes(axes, len(counts[character_type]))\n","        for ax, (chp, freq) in zip(axes, counts[character_type].items()):\n","            # Abbreviate names for plots\n","            labels = []\n","            data = []\n","            for k, v in freq.items():\n","                labels.append(abbreviate_entity(k))\n","                data.append(v)\n","            barplot(data, labels, xlabel=f'Chapter {chp}', ylim=ylim, ax=ax)\n","        print(f'{story} - {character_type}')\n","        if show:\n","            plt.show()\n","\n","\n","def plot_ner_counts_story(story, counts, *, show=False):\n","    ylim = (0, get_max_frequency_from_nested2_map(counts))\n","    for character_type in CHARACTERS_NAMES[story].keys():\n","        freq = counts[character_type][0]\n","\n","        # Abbreviate names for plots\n","        labels = []\n","        data = []\n","        for k, v in freq.items():\n","            labels.append(abbreviate_entity(k))\n","            data.append(v)\n","\n","        barplot(data, labels, xlabel='', ylim=ylim)\n","        print(f'{story} - {character_type}')\n","        if show:\n","            plt.show()\n","\n","\n","def plot_ner_counts_story_with_paragraphs(story, counts, *, show=False):\n","    ylim = (0, get_max_frequency_from_nested2_map(counts))\n","    for character_type in CHARACTERS_NAMES[story].keys():\n","        ns = int(np.ceil(np.sqrt(len(counts[character_type]))))\n","        fig, axes = plt.subplots(ns, ns, constrained_layout=True)\n","        axes = trim_axes(axes, len(counts[character_type]))\n","        for ax, (par, freq) in zip(axes, counts[character_type].items()):\n","            # Abbreviate names for plots\n","            labels = []\n","            data = []\n","            for k, v in freq.items():\n","                labels.append(abbreviate_entity(k))\n","                data.append(v)\n","            barplot(data, labels, xlabel=f'Paragraph {par}', ylim=ylim, ax=ax)\n","        print(f'{story} - {character_type}')\n","        if show:\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YFV62f475M4p"},"source":["###$\\color{brown}{\\rm Frequency~Count}$\n","For vocabulary and keywords/entities"]},{"cell_type":"code","metadata":{"id":"UOEgIn2Cnbcb","colab_type":"code","colab":{}},"source":["def get_keywords_map(text, span=None, keywords=[], *, spans_map=None):\n","    if spans_map is None:\n","        spans_map = collections.defaultdict(list)\n","\n","    # NOTE: Allow cases where token is a prefix/compound of a longer token\n","    for kw in keywords:\n","        spans_map[kw].extend(tokenize(\n","            text,\n","            span,\n","            fr'(?<![a-zA-Z0-9]){kw}',\n","        ))\n","    return spans_map\n","\n","\n","def generate_frequency_map(spans_map, *, threshold=None):\n","    freq = collections.defaultdict(int)\n","    for k, v in spans_map.items():\n","        if threshold is None or len(v) >= threshold:\n","            freq[k] = len(v)\n","    return freq\n","\n","\n","def convert_spans_to_counts_map(spans_map):\n","    return {\n","        key: len(spans)\n","        for key, spans in spans_map.items()\n","    }\n","\n","\n","def get_vocabulary(text, span=None, *, vocab=None):\n","    return (\n","        list(vocab) if vocab else []\n","    ) + [\n","        get_text_from_span(text, token_span)\n","        for token_span in get_tokens(text, span)\n","    ]\n","\n","\n","def get_vocabulary_map(text, span=None, *, spans_map=None):\n","    if spans_map is None:\n","        spans_map = collections.defaultdict(list)\n","\n","    for token_span in get_tokens(text, span):\n","        token = get_text_from_span(text, token_span)\n","        spans_map[token].append(token_span)\n","    return spans_map\n","\n","\n","def get_frequent_items(data, n=10):\n","    d = collections.Counter(data)\n","    return dict(d.most_common(n))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C7r26-e6QFKB"},"source":["###$\\color{brown}{\\rm First~Time~Occurrences}$"]},{"cell_type":"code","metadata":{"id":"nX2xlrjtQLkg","colab_type":"code","colab":{}},"source":["def get_first_occurrences(story_spans):\n","    \"\"\"Get spans of first occurrences.\"\"\"\n","    firstoccurrences = {}\n","    for character_type, sections in story_spans.items():\n","        firstoccurrences[character_type] = {}\n","        for section, characters in sections.items():\n","            for character in characters.keys():\n","                spans = story_spans[character_type][section][character]\n","                if character not in firstoccurrences[character_type] and spans:\n","                    firstoccurrences[character_type][character] = spans[0]\n","    return firstoccurrences\n","\n","\n","def get_span_location_with_chapters(text, span, search_span, *, verbose=False):\n","    \"\"\"Get text elements of span occurrence.\"\"\"\n","    location = {'chapter': None, 'paragraph': None, 'sentence': None, 'sentence_chp': None}\n","    for ichp, chp_span in enumerate(get_chapters(text, span), start=1):\n","        csent = 0  # chapter based sentence\n","        for ipar, par_span in enumerate(get_paragraphs(text, chp_span), start=1):\n","            for isent, sent_span in enumerate(get_sentences(text, par_span), start=1):\n","                csent += 1\n","                if verbose:\n","                    print(f'Chapter {ichp}, Paragraph {ipar}, Sentence {isent}, Sentence (Chp) {csent}')\n","                    print(get_text_from_span(text, sent_span))\n","                if search_span[0] >= sent_span[0] and search_span[1] <= sent_span[1]:\n","                    location['chapter'] = ichp\n","                    location['paragraph'] = ipar\n","                    location['sentence'] = isent\n","                    location['sentence_chp'] = csent\n","                    return location\n","\n","\n","def get_span_location(text, span, search_span, *, verbose=False):\n","    \"\"\"Get text elements of span occurrence.\"\"\"\n","    location = {'paragraph': None, 'sentence': None, 'sentence_text': None}\n","    csent = 0  # text based sentence\n","    for ipar, par_span in enumerate(get_paragraphs(text, span), start=1):\n","        for isent, sent_span in enumerate(get_sentences(text, par_span), start=1):\n","            csent += 1\n","            if verbose:\n","                print(f'Paragraph {ipar}, Sentence {isent}, Sentence (Text) {csent}')\n","                print(get_text_from_span(text, sent_span))\n","            if search_span[0] >= sent_span[0] and search_span[1] <= sent_span[1]:\n","                location['paragraph'] = ipar\n","                location['sentence'] = isent\n","                location['sentence_text'] = csent\n","                return location"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdW55Bdl9H-2","colab_type":"text"},"source":["###$\\color{brown}{\\rm Neighboring~Words}$"]},{"cell_type":"code","metadata":{"id":"3OJH1SWm9Iyo","colab_type":"code","colab":{}},"source":["STOPWORDS = {\n","    'yours', 'do', 'might', 'although', 'all', 'he', \"'s\", 'wherein',\n","    'themselves', 'used', 'anyone', 'others', 'whom', 'off', 'doing',\n","    'she', 'no', 'even', 'behind', 'them', 'done', 'none', 'beside',\n","    'whither', 'yet', 'but', 'perhaps', 'one', 'its', 'thereby', 'on',\n","    'hereby', 'nine', 'just', 'ca', 'front', \"'d\", 'also', 'across',\n","    'seems', 'towards', 'together', 'itself', 'four', 'that', 'why', 'it',\n","    'so', 'three', 'down', 'keep', 'sixty', 'empty', 'above', 'whose',\n","    'between', 'hence', 'two', 'be', 'however', 'nothing', 'are', 'whence',\n","    're', 'beyond', 'being', 'nowhere', 'always', 'was', 'via', 'mine',\n","    'ourselves', 'quite', 'when', 'only', 'should', 'amongst', 'before',\n","    'from', 'any', 'most', 'how', 'same', 'if', 'latter', 'something',\n","    'fifty', 'an', 'have', 'who', 'too', 'up', 'ours', 'which',\n","    'beforehand', 'else', 'sometimes', 'to', 'either', 'really', 'take',\n","    'such', 'go', 'again', 'into', 'a', 'per', 'anyhow', 'anything',\n","    'elsewhere', 'hundred', 'afterwards', 'we', 'since', 'yourselves',\n","    'both', 'top', 'formerly', \"'m\", 'her', 'alone', 'whereas', 'becoming',\n","    'what', \"n't\", 'back', 'or', \"'ll\", 'never', 'everyone', 'various',\n","    'then', 'over', 'against', 'twelve', 'herself', 'those', 'they',\n","    'became', 'thereafter', 'forty', 'latterly', 'seeming', 'see', 'of',\n","    'much', 'thereupon', 'regarding', 'get', 'give', 'by', 'indeed', \"'ve\",\n","    'thus', 'part', 'can', 'still', 'is', 'nor', 'first', 'eight',\n","    'nevertheless', 'another', 'along', 'i', 'former', 'someone',\n","    'without', 'noone', 'whoever', 'becomes', 'about', 'through', 'unless',\n","    'fifteen', 'namely', 'anywhere', 'will', 'as', 'each', 'during', 'few',\n","    'become', 'their', 'hereafter', 'could', 'third', 'thru', 'somehow',\n","    'in', 'bottom', 'am', 'seem', 'otherwise', 'here', 'several', 'say',\n","    'would', 'our', 'for', 'due', 'move', 'somewhere', 'under', 'himself',\n","    'already', 'with', 'except', 'mostly', 'amount', 'more', 'you', 'his',\n","    'almost', 'every', 'upon', 'throughout', 'often', 'below', 'been',\n","    'whatever', 'eleven', 'whole', 'within', 'cannot', 'five', 'him',\n","    'hers', 'yourself', 'next', 'once', 'around', \"'re\", 'thence', 'using',\n","    'does', 'until', 'were', 'make', 'onto', 'us', 'your', 'while',\n","    'because', 'some', 'show', 'full', 'everything', 'did', 'after',\n","    'call', 'now', 'the', 'meanwhile', 'many', 'whereupon', 'everywhere',\n","    'me', 'name', 'not', 'seemed', 'least', 'must', 'six', 'less',\n","    'serious', 'there', 'whereby', 'whether', 'own', 'and', 'whereafter',\n","    'has', 'may', 'neither', 'where', 'ever', 'wherever', 'made',\n","    'moreover', 'well', 'myself', 'among', 'please', 'other', 'out',\n","    'this', 'therein', 'rather', 'though', 'hereupon', 'besides', 'had',\n","    'at', 'twenty', 'ten', 'these', 'my', 'than', 'side', 'nobody', 'very',\n","    'last', 'sometime', 'toward', 'herein', 'whenever', 'further',\n","    'anyway', 'enough', 'therefore', 'put',\n","}\n","\n","\n","# Get neighbor words (even across sentences)\n","def get_neighbor_words_for_character(text, spans, characters, alias_list, *, n=3, stopwords=None):\n","    neighbors = {}\n","    for character, cspans in characters.items():\n","        neighbors[character] = {}\n","        neighbors[character]['before'] = collections.defaultdict(int)\n","        neighbors[character]['after'] = collections.defaultdict(int)\n","        # neighbors[character]['before_spans'] = collections.defaultdict(list)\n","        # neighbors[character]['after_spans'] = collections.defaultdict(list)\n","\n","        aliases = []\n","        for clist in alias_list:\n","            if character == clist[0]:\n","                aliases = [alias.lower() for alias in clist]\n","                break\n","\n","        # Combine token and character spans \n","        tmp = copy.deepcopy(spans)\n","        tmp.extend(cspans)\n","        spans2 = get_nonoverlapped_spans(tmp, join=False)\n","\n","        last_idx = 0\n","        for cspan in cspans:\n","            try:\n","                idx = spans2.index(cspan, last_idx)\n","                last_idx = idx\n","            except ValueError:\n","                continue\n","\n","            # Hack to dismiss names as neighbors\n","            prev_n = 0\n","            _n = 1\n","            while prev_n < n:\n","                prev_idx = idx - _n\n","                _n += 1\n","                if prev_idx >= 0:\n","                    token = spans2[prev_idx]\n","                    word = get_text_from_span(text, token)\n","\n","                    valid = True\n","                    for alias in aliases:\n","                        if word in alias or word.replace(' ', '_') in alias:\n","                            valid = False\n","                            break\n","\n","                    if valid and stopwords:\n","                        valid = word not in stopwords\n","\n","                    if not valid:\n","                        continue\n","                    \n","                    prev_n += 1\n","                    neighbors[character]['before'][word] += 1\n","                    # neighbors[character]['before_spans'][word].append(token)\n","                else:\n","                    break\n","\n","            after_n = 0\n","            _n = 1\n","            while after_n < n:\n","                after_idx = idx + _n\n","                _n += 1\n","                if after_idx < len(spans2):\n","                    token = spans2[after_idx]\n","                    word = get_text_from_span(text, token)\n","\n","                    valid = True\n","                    for alias in aliases:\n","                        if word in alias or word.replace(' ', '_') in alias:\n","                            valid = False\n","                            break\n","\n","                    if valid and stopwords:\n","                        valid = word not in stopwords\n","\n","                    if not valid:\n","                        continue\n","                    \n","                    after_n += 1\n","                    neighbors[character]['after'][word] += 1\n","                    # neighbors[character]['after_spans'][word].append(token)\n","                else:\n","                    break\n","\n","    return neighbors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dg59EqZHUi1l","colab_type":"text"},"source":["###$\\color{brown}{\\rm Visualization}$"]},{"cell_type":"code","metadata":{"id":"5suCpM1DUh9n","colab_type":"code","colab":{}},"source":["def trim_axes(axes, n):\n","    axes = axes.flat\n","    for ax in axes[n:]:\n","        ax.remove()\n","    return axes[:n]\n","\n","\n","def visualize_co_occurrence(data, keywords_rows, closeness_words_columns):\n","    # Create a dataframe from the provided data\n","    df = pandas.DataFrame(\n","        data,\n","        index=keywords_rows,\n","        columns=closeness_words_columns,\n","    )\n","\n","    # Set plot size according to the number of cols and rows\n","    plt.figure(figsize=(len(keywords_rows), len(closeness_words_columns)))\n","\n","    # Set color of heatmap\n","    hdl = sns.heatmap(df, cmap=\"YlGnBu\", annot=True, linewidths=.5)\n","\n","    # Rotate text\n","    loc_x, labels_x = plt.xticks()\n","    loc_y, labels_y = plt.yticks()\n","    hdl.set_xticklabels(labels_x, rotation=58)\n","    hdl.set_yticklabels(labels_y, rotation=0)\n","\n","\n","def barplot(data, labels, *, xlabel='Word', ylabel='Frequency', ylim=None, ax=None):\n","    # Prepare the data to pandas\n","    data_ = [labels, data]\n","    data_ = np.asarray(data_).transpose()\n","\n","    # Create a dataframe from the provided data\n","    df = pandas.DataFrame(data_, columns=[xlabel, ylabel])\n","    hdl = sns.barplot(x=xlabel, y=ylabel, data=df, palette=\"Blues_d\", ax=ax)\n","    plt.setp(hdl.get_xticklabels(), rotation=45)\n","\n","    if ylim:\n","        if ax:\n","            ax.set(ylim=ylim)\n","        else:\n","            plt.ylim(*ylim)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1g4VrZThNgJT","colab_type":"text"},"source":["Example of co-occurrence"]},{"cell_type":"code","metadata":{"id":"55rQOyj6NayZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":476},"outputId":"f1a20d2f-7721-4680-b275-e560291b5f50"},"source":["# Example of expected format of data that the method needs\n","rows_example = ['Holmes', 'Watson', 'criminal', 'treasure', 'man', 'poison', 'killed']\n","\n","columns_example = [\"P. Moriarty\", \"T. Baldwin\", \"J. Hope\",\"J. Small\",\"Tonga\",\"J. Stapleton\",\"J. Turner\"]\n","data_example = [[1,1,0,0,0,0,0],[0,0,0,0,1,0,0],[1,1,0,0,0,1,0],[0,0,0,1,1,0,0],[0,0,0,1,0,0,1],[0,0,0,0,1,0,0],[0,0,0,0,2,0,0]]\n","\n","# Plot\n","visualize_co_occurrence(data_example,rows_example,columns_example)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"I2K0IrUFN4mi","colab_type":"text"},"source":["Example of word count histogram"]},{"cell_type":"code","metadata":{"id":"zgkC-LT7OASA","colab_type":"code","colab":{}},"source":["# Example of expected format of data that the method needs\n","labels_example = [\"murder\", \"guilty\", \"suspect\", \"assassin\"]\n","data_example = [5,8,3,1]\n","\n","# Plot\n","barplot(data_example,labels_example)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J26kopyFSL6C","colab_type":"text"},"source":["###$\\color{brown}{\\rm Drivers}$"]},{"cell_type":"markdown","metadata":{"id":"45kpuKOWeTav","colab_type":"text"},"source":["# Get text from stories"]},{"cell_type":"code","metadata":{"id":"FMoI5rT9chVu","colab_type":"code","colab":{}},"source":["corpus = get_corpus('The Valley of Fear')\n","corpus_l = corpus.lower()\n","spans = get_text(corpus_l)\n","text = get_text_from_span(corpus_l, spans[0])\n","print(text[:100])\n","print('-' * 80)\n","\n","corpus = get_corpus('A Study in Scarlet')\n","corpus_l = corpus.lower()\n","spans = get_parts(corpus_l, n=1)  # n = Part\n","text = get_text_from_span(corpus_l, spans[0])\n","print(text[:100])\n","print('-' * 80)\n","\n","corpus = get_corpus('The Sign of the Four')\n","corpus_l = corpus.lower()\n","spans = get_text(corpus_l)\n","text = get_text_from_span(corpus_l, spans[0])\n","print(text[:100])\n","print('-' * 80)\n","\n","corpus = get_corpus('The Hound of the Baskervilles')\n","corpus_l = corpus.lower()\n","spans = get_text(corpus_l)\n","text = get_text_from_span(corpus_l, spans[0])\n","print(text[:100])\n","print('-' * 80)\n","\n","corpus = get_corpus('The Boscombe Valley Mystery')\n","corpus_l = corpus.lower()\n","spans = get_adventures(corpus_l, n=4)\n","text = get_text_from_span(corpus_l, spans[0])\n","print(text[:100])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5_Dh2WOgDb8","colab_type":"text"},"source":["# Negative words frequency"]},{"cell_type":"code","metadata":{"id":"nOF8BoVltsmr","colab_type":"code","colab":{}},"source":["def get_negative_words(negative_words):\n","    \"\"\"\n","    Get list of negative words\n","    \"\"\"\n","    return [negative_words[match.start():match.end()] for match in re.finditer(r'(?<=\\n)[a-zA-Z]+(?=\\n)', negative_words)]\n","    # return [negative_words[match.start():match.end()] for match in re.finditer(r'(?<=\\n)[a-zA-Z]+(?=\\n)', negative_words)]\n","\n","\n","def get_top_negative_words(corpus, negative_list, *, top=20):\n","    \"\"\"\n","    Get top list of negative words\n","    \"\"\"\n","    frequency_list = []\n","    for word in negative_list:\n","        result_list = [match.span() for match in re.finditer(fr'(?<![a-zA-Z0-9]){word}', corpus)]\n","        frequency_list.append(len(result_list))\n","    \n","    # Sort results\n","    temp_list = np.asarray(list(zip(negative_list,frequency_list)), dtype = [('word', np.unicode_, 16), ('frequency', int)] )\n","    sorted_list = np.sort(temp_list, order='frequency', kind=\"quicksort\")\n","    sorted_list = sorted_list[::-1]\n","\n","    return sorted_list[:top]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"it1VqaovmSHz","colab_type":"code","colab":{}},"source":["# Get negative words\n","url = \"https://raw.githubusercontent.com/edponce/DoyleInvestigators/develop/negative-words.txt\"\n","negative_words = get_corpus_from_url(url)\n","result_negative = get_negative_words(negative_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJbfK9lSlJSX","colab_type":"code","colab":{}},"source":["story = 'The Valley of Fear'\n","\n","# Get corpus (use all text between Gutenberg tags)\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","text = get_text_from_span(corpus_l, get_text(corpus_l)[0])\n","\n","# Get count\n","results = get_top_negative_words(text, result_negative, top=20)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pS3UWWrylSfC","colab_type":"code","colab":{}},"source":["story = 'A Study in Scarlet'\n","\n","# Get corpus (use all text between Gutenberg tags)\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","spans = get_parts(corpus_l, n=1) # n = Part\n","text = get_text_from_span(corpus_l, spans[0])\n","\n","# Get count\n","results = get_top_negative_words(text, result_negative, top=20)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYj-DHkPl4_-","colab_type":"code","colab":{}},"source":["story = 'The Sign of the Four'\n","\n","# Get corpus (use all text between Gutenberg tags)\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","text = get_text_from_span(corpus_l, get_text(corpus_l)[0])\n","\n","# Get count\n","results = get_top_negative_words(text, result_negative, top=20)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUIzkHwUmClo","colab_type":"code","colab":{}},"source":["story = 'The Hound of the Baskervilles'\n","\n","# Get corpus (use all text between Gutenberg tags)\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","text = get_text_from_span(corpus_l, get_text(corpus_l)[0])\n","\n","# Get count\n","results = get_top_negative_words(text, result_negative, top=20)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P1GGmcEKmHdp","colab_type":"code","colab":{}},"source":["story = 'The Boscombe Valley Mystery'\n","\n","# Get corpus (use all text between Gutenberg tags)\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","spans = get_adventures(corpus_l, n=4)\n","text = get_text_from_span(corpus_l, spans[0])\n","\n","# Get count\n","results = get_top_negative_words(text, result_negative, top=20)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JGmhR6ePSgI","colab_type":"text"},"source":["# Crime Detection"]},{"cell_type":"code","metadata":{"id":"zOHVgrENEUb2","colab_type":"code","colab":{}},"source":["def crime_story_with_chapters(keywords, text, span=None):\n","    story_spans = {}\n","    story_counts = {}\n","    for n, chp_span in enumerate(get_chapters(text, span), start=1):\n","        story_spans[n] = {}\n","        story_counts[n] = {}\n","        for kw in keywords:\n","            story_spans[n].update(search_entity(kw, text, span))\n","            story_counts[n] = convert_spans_to_counts_map(story_spans[n])\n","    return story_spans, story_counts\n","\n","\n","def crime_story(keywords, text, span=None):\n","    story_spans = {}\n","    story_counts = {}\n","    story_spans[0] = {}\n","    story_counts[0] = {}\n","    for kw in keywords:\n","        story_spans[0].update(search_entity(kw, text, span))\n","        story_counts[0] = convert_spans_to_counts_map(story_spans[0])\n","    return story_spans, story_counts\n","\n","\n","def get_first_crime(story_spans):\n","    \"\"\"Get spans of first crime occurrences.\"\"\"\n","    firstoccurrences = {}\n","    for section, keywords in story_spans.items():\n","        for kw, spans in keywords.items():\n","            if kw not in firstoccurrences and spans:\n","                firstoccurrences[kw] = spans[0]\n","    return firstoccurrences\n","\n","\n","def plot_crime_counts_story_with_chapters(story, counts, *, show=False):\n","    ylim = (0, get_max_frequency_from_nested_map(counts))\n","    ns = int(np.ceil(np.sqrt(len(counts))))\n","    fig, axes = plt.subplots(ns, ns, constrained_layout=True)\n","    axes = trim_axes(axes, len(counts))\n","    for ax, (chp, freq) in zip(axes, counts.items()):\n","        # Abbreviate names for plots\n","        labels = []\n","        data = []\n","        for k, v in freq.items():\n","            labels.append(k)\n","            data.append(v)\n","        barplot(data, labels, xlabel=f'Chapter {chp}', ylim=ylim, ax=ax)\n","    print(f'{story}')\n","    if show:\n","        plt.show()\n","\n","\n","def plot_ner_counts_story(story, counts, *, show=False):\n","    ylim = (0, get_max_frequency_from_nested2_map(counts))\n","    for character_type in CHARACTERS_NAMES[story].keys():\n","        freq = counts[character_type][0]\n","\n","        # Abbreviate names for plots\n","        labels = []\n","        data = []\n","        for k, v in freq.items():\n","            labels.append(abbreviate_entity(k))\n","            data.append(v)\n","\n","        barplot(data, labels, xlabel='', ylim=ylim)\n","        print(f'{story} - {character_type}')\n","        if show:\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idDHTu4ICWg3","colab_type":"code","colab":{}},"source":["# Search keywords\n","CRIME_KEYWORDS = [\n","    'dead', 'death', 'murder', 'crime', 'hurt', 'blood', 'treasure', 'suffer',\n","    'guilty', 'assassin', 'pain', 'theft', 'steal', 'victim', 'poison',\n","    'gunshot', 'criminal', 'wound', 'attack',\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"a7il19VSIVst"},"source":["### The Valley of Fear, The Sign of the Four, The Hound of the Baskervilles"]},{"cell_type":"code","metadata":{"id":"VfllduiHIX-m","colab_type":"code","colab":{}},"source":["story = 'The Valley of Fear'\n","#story = 'The Sign of the Four'\n","#story = 'The Hound of the Baskervilles'\n","\n","# Get corpus span\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","spans = get_text(corpus_l)\n","span = spans[0]\n","\n","\n","# Full story\n","story_spans, story_counts = crime_story_with_chapters(CRIME_KEYWORDS, corpus_l, span)\n","plot_crime_counts_story_with_chapters(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","#pp.pprint(story_spans)\n","#pp.pprint(story_counts)\n","\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_crime(story_spans)\n","# print(first_occurrences)\n","\n","# Find location of first span\n","first_locations = {}\n","for kw, kw_span in first_occurrences.items():\n","    location = get_span_location(corpus_l, span, kw_span, verbose=False)\n","    first_locations[kw] = location\n","\n","print(story)\n","#pp = pprint.PrettyPrinter(indent=2)\n","#pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_tPx_UcYJUQD"},"source":["### A Study in Scarlet\n"]},{"cell_type":"code","metadata":{"id":"5emLis8UJZ6Q","colab_type":"code","colab":{}},"source":["story = 'A Study in Scarlet'\n","\n","# Get corpus span\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","spans = get_parts(corpus_l, n=1)  # n = Part\n","span = spans[0]\n","\n","\n","# Full story\n","story_spans, story_counts = crime_story_with_chapters(CRIME_KEYWORDS, corpus_l, span)\n","plot_crime_counts_story_with_chapters(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","#pp.pprint(story_spans)\n","pp.pprint(story_counts)\n","\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_crime(story_spans)\n","# print(first_occurrences)\n","\n","# Find location of first span\n","first_locations = {}\n","for kw, kw_span in first_occurrences.items():\n","    location = get_span_location(corpus_l, span, kw_span, verbose=False)\n","    first_locations[kw] = location\n","\n","print(story)\n","pp = pprint.PrettyPrinter(indent=2)\n","pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rqz3wyWlGltJ"},"source":["### The Boscombe Valley Mystery"]},{"cell_type":"code","metadata":{"id":"af6Ne8K-CPBU","colab_type":"code","colab":{}},"source":["story = 'The Boscombe Valley Mystery'\n","\n","# Get corpus span\n","corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","spans = get_adventures(corpus_l, n=4)\n","span = spans[0]\n","\n","# Full story\n","story_spans, story_counts = crime_story(CRIME_KEYWORDS, corpus_l, span)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","#pp.pprint(story_spans)\n","pp.pprint(story_counts)\n","\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_crime(story_spans)\n","# print(first_occurrences)\n","\n","# Find location of first span\n","first_locations = {}\n","for kw, kw_span in first_occurrences.items():\n","    location = get_span_location(corpus_l, span, kw_span, verbose=False)\n","    first_locations[kw] = location\n","\n","print(story)\n","pp = pprint.PrettyPrinter(indent=2)\n","pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S5jJimkLrG5m","colab_type":"text"},"source":["#### Utility functions for location of crime"]},{"cell_type":"code","metadata":{"id":"mPwEPtO1X562","colab_type":"code","colab":{}},"source":["# Identify paragraph and sentence based on a keyword.\n","# This is used for crime detection analysis.\n","search_pair = ['blood', 'mysterious']\n","gp = 0\n","found = False\n","\n","c = get_chapters(text, span)\n","for k, _c in enumerate(c, start=1):\n","    p = get_paragraphs(text, _c)\n","    for i, _p in enumerate(p, start=1):\n","        gp += 1\n","        s = get_sentences(text, _p)\n","        for j, _s in enumerate(s, start=1):\n","            print(f'C{k}, GP{gp}, S{j}')\n","            t = get_text_from_span(text, _s)\n","            print(f'C{k}, P{i}, S{j} ------------------------\\n', t)\n","            if search_pair[0] in t and search_pair[1] in t:\n","                found = True\n","                break\n","        if found: break\n","    if found: break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_8wGLKhmTRn","colab_type":"code","colab":{}},"source":["# Identify paragraph and sentence based on a keyword.\n","# This is used for crime detection analysis.\n","search_pair = ['murdered', 'man']\n","found = False\n","\n","p = get_paragraphs(text, span)\n","for i, _p in enumerate(p, start=1):\n","    s = get_sentences(text, _p)\n","    for j, _s in enumerate(s, start=1):\n","        t = get_text_from_span(text, _s)\n","        if search_pair[0] in t and search_pair[1] in t:\n","            print(f'P{i}, S{j} ------------------------\\n', t)\n","            found = True\n","            break\n","    if found: break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xJTBNIkkRB-","colab_type":"text"},"source":["# Story structure"]},{"cell_type":"code","metadata":{"id":"3Q1TgcxbkXb6","colab_type":"code","colab":{}},"source":["def count_text_structure(text, span=None, structure=None):\n","    if structure is None:\n","        structure = collections.defaultdict(int)\n","\n","    for par_span in get_paragraphs(text, span):\n","        structure['Paragraphs'] += 1\n","        for sent_span in get_sentences(text, par_span):\n","            structure['Sentences'] += 1\n","            for tok_span in get_tokens(text, sent_span):\n","                structure['Words'] += 1\n","    return structure"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCvzFwI5qXV5","colab_type":"code","colab":{}},"source":["story = 'The Valley of Fear'\n","corpus = get_corpus(story)\n","text = corpus.lower()\n","structure = collections.defaultdict(int)\n","for part_span in get_parts(text):\n","    structure['Parts'] += 1\n","    for chp_span in get_chapters(text, part_span):\n","        structure['Chapters'] += 1\n","        count_text_structure(text, chp_span, structure)\n","structure['Epilogue'] = 1\n","span = get_text(text)[0]\n","structure['Characters'] = span[1] - span[0]\n","count_text_structure(text, get_epilogue(text)[0], structure)\n","\n","pp = pprint.PrettyPrinter(indent=4)\n","pp.pprint(structure)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G_tuRLPqct3","colab_type":"code","colab":{}},"source":["story = 'A Study in Scarlet'\n","corpus = get_corpus(story)\n","text = corpus.lower()\n","structure = collections.defaultdict(int)\n","for part_span in get_parts(text):\n","    structure['Parts'] += 1\n","    for chp_span in get_chapters(text, part_span):\n","        structure['Chapters'] += 1\n","        count_text_structure(text, chp_span, structure)\n","span = get_text(text)[0]\n","structure['Characters'] = span[1] - span[0]\n","\n","pp = pprint.PrettyPrinter(indent=4)\n","pp.pprint(structure)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oh4204v7q4ov","colab_type":"code","colab":{}},"source":["story = 'The Sign of the Four'\n","corpus = get_corpus(story)\n","text = corpus.lower()\n","structure = collections.defaultdict(int)\n","for chp_span in get_chapters(text):\n","    structure['Chapters'] += 1\n","    count_text_structure(text, chp_span, structure)\n","span = get_text(text)[0]\n","structure['Characters'] = span[1] - span[0]\n","\n","pp = pprint.PrettyPrinter(indent=4)\n","pp.pprint(structure)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ4K1uGCqua7","colab_type":"code","colab":{}},"source":["story = 'The Hound of the Baskervilles'\n","corpus = get_corpus(story)\n","text = corpus.lower()\n","structure = collections.defaultdict(int)\n","for chp_span in get_chapters(text):\n","    structure['Chapters'] += 1\n","    count_text_structure(text, chp_span, structure)\n","span = get_text(text)[0]\n","structure['Characters'] = span[1] - span[0]\n","\n","pp = pprint.PrettyPrinter(indent=4)\n","pp.pprint(structure)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1E2wmoJoqu1t","colab_type":"code","colab":{}},"source":["story = 'The Boscombe Valley Mystery'\n","corpus = get_corpus(story)\n","text = corpus.lower()\n","structure = collections.defaultdict(int)\n","span = get_adventures(text, n=4)[0]\n","count_text_structure(text, span, structure)\n","structure['Characters'] = span[1] - span[0]\n","\n","pp = pprint.PrettyPrinter(indent=4)\n","pp.pprint(structure)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BeWCIOHwkvRC","colab_type":"text"},"source":["# Find character entities"]},{"cell_type":"code","metadata":{"id":"NUtoC_WUk4Z3","colab_type":"code","colab":{}},"source":["story = 'The Valley of Fear'\n","\n","# Select part(s)\n","# spans = get_parts(get_corpus(story).lower(), n=1)  # n = Part\n","# span = spans[0]  # [i] = Part i+1\n","span = None  # all Parts or if no Parts\n","\n","# Per chapter\n","story_spans, story_counts = ner_story_with_chapters(story, span)\n","plot_ner_counts_story_with_chapters(story, story_counts, show=False)\n","\n","# Full story\n","# story_spans, story_counts = ner_story(story, span)\n","# plot_ner_counts_story(story, story_counts, show=False)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","# pp.pprint(story_spans)\n","pp.pprint(story_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LL9Sdxd4V2D2","colab":{}},"source":["story = 'A Study in Scarlet'\n","\n","# Select part(s)\n","spans = get_parts(get_corpus(story).lower())  # n = Part\n","span = spans[0]  # [i] = Part i+1\n","\n","# Per chapter\n","story_spans, story_counts = ner_story_with_chapters(story, span)\n","plot_ner_counts_story_with_chapters(story, story_counts, show=True)\n","\n","# Full story\n","# story_spans, story_counts = ner_story(story, span)\n","# plot_ner_counts_story(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","# pp.pprint(story_spans)\n","pp.pprint(story_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPUB6HN-oMRj","colab_type":"code","colab":{}},"source":["story = 'The Sign of the Four'\n","\n","# Per chapter\n","story_spans, story_counts = ner_story_with_chapters(story)\n","plot_ner_counts_story_with_chapters(story, story_counts, show=True)\n","\n","# Full story\n","# story_spans, story_counts = ner_story(story)\n","# plot_ner_counts_story(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","# pp.pprint(story_spans)\n","pp.pprint(story_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mZKxmKulVwmS","colab":{}},"source":["story = 'The Hound of the Baskervilles'\n","\n","# Per chapter\n","story_spans, story_counts = ner_story_with_chapters(story)\n","plot_ner_counts_story_with_chapters(story, story_counts, show=True)\n","\n","# Full story\n","# story_spans, story_counts = ner_story(story)\n","# plot_ner_counts_story(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","# pp.pprint(story_spans)\n","pp.pprint(story_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaUvweLFGulK","colab_type":"code","colab":{}},"source":["story = 'The Boscombe Valley Mystery'\n","spans = get_adventures(get_corpus(story).lower(), n=4)\n","span = spans[0]\n","\n","# Per paragraph\n","# story_spans, story_counts = ner_story_with_paragraphs(story, span)\n","# plot_ner_counts_story_with_paragraphs(story, story_counts, show=True)\n","\n","# Full story\n","story_spans, story_counts = ner_story(story, span)\n","plot_ner_counts_story(story, story_counts, show=True)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","# pp.pprint(story_spans)\n","pp.pprint(story_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INOc_W1sB7fB","colab_type":"text"},"source":["## Identify first-time occurrences"]},{"cell_type":"markdown","metadata":{"id":"9OKynQiwtC9v","colab_type":"text"},"source":["### The Valley of Fear, The Sign of the Four, The Hound of the Baskervilles"]},{"cell_type":"code","metadata":{"id":"77nhsqcjCHN9","colab_type":"code","colab":{}},"source":["print(story)\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_occurrences(story_spans)\n","# print(first_occurrences)\n","\n","# Get corpus span\n","corpus_l = get_corpus(story).lower()\n","spans = get_text(corpus_l)\n","span = spans[0]\n","\n","# Find location of first span\n","first_locations = {}\n","for character_type, characters in first_occurrences.items():\n","    first_locations[character_type] = {}\n","    for character in characters:\n","        location = get_span_location_with_chapters(corpus_l, span, first_occurrences[character_type][character], verbose=False)\n","        first_locations[character_type][character] = location\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yIqDSTkTiZgg","colab_type":"text"},"source":["### A Study in Scarlet"]},{"cell_type":"code","metadata":{"id":"0Pe2X6voifdH","colab_type":"code","colab":{}},"source":["print(story)\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_occurrences(story_spans)\n","# print(first_occurrences)\n","\n","# Get corpus span\n","text = get_corpus(story).lower()\n","spans = get_parts(text)  # n = Part\n","span = spans[0]  # [i] = Part i+1\n","\n","# Find location of first span\n","first_locations = {}\n","for character_type, characters in first_occurrences.items():\n","    first_locations[character_type] = {}\n","    for character in characters:\n","        location = get_span_location_with_chapters(text, span, first_occurrences[character_type][character], verbose=False)\n","        first_locations[character_type][character] = location\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rPrRVe7wtZlj","colab_type":"text"},"source":["### The Boscombe Valley Mystery"]},{"cell_type":"code","metadata":{"id":"JddrNJXupDcI","colab_type":"code","colab":{}},"source":["print(story)\n","\n","# Get span of first occurrence\n","first_occurrences = get_first_occurrences(story_spans)\n","# print(first_occurrences)\n","\n","# Get corpus span\n","text = get_corpus(story).lower()\n","spans = get_adventures(text, n=4)\n","span = spans[0]\n","\n","# Find location of first span\n","first_locations = {}\n","for character_type, characters in first_occurrences.items():\n","    first_locations[character_type] = {}\n","    for character in characters:\n","        location = get_span_location(text, span, first_occurrences[character_type][character], verbose=False)\n","        first_locations[character_type][character] = location\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","pp.pprint(first_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OOkZa5g2jlru","colab_type":"text"},"source":["## Neighbor words"]},{"cell_type":"code","metadata":{"id":"GXfOrm_sjyY-","colab_type":"code","colab":{}},"source":["# NOTE: Need to run \"Find character entities\" as an initial step.\n","\n","print(story_spans)\n","\n","# Merge perpetrators spans across story chapters/sections\n","perpetrators = {}\n","for section, characters in story_spans['perpetrators'].items():\n","    for character, spans in characters.items():\n","        if character not in perpetrators:\n","            perpetrators[character] = []\n","        perpetrators[character].extend(spans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vPCigW2xlYZ","colab_type":"code","colab":{}},"source":["corpus = get_corpus(story)\n","corpus_l = corpus.lower()\n","#spans = get_text(corpus_l)\n","spans = get_chapters(corpus_l)\n","tok_spans = get_tokens(corpus_l, (spans[0][0], spans[4][1]))\n","\n","print(len(tok_spans))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7UK-ti9TT9-","colab_type":"code","colab":{}},"source":["# Method 1: Without stopwords\n","perpetrator_neighbors = get_neighbor_words_for_character(corpus_l, tok_spans, perpetrators, CHARACTERS_NAMES[story]['perpetrators'])\n","pp.pprint(perpetrator_neighbors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flvPa-wmgG6-","colab_type":"code","colab":{}},"source":["# Method 2: With stopwords\n","perpetrator_neighbors_stop = get_neighbor_words_for_character(corpus_l, tok_spans, perpetrators, CHARACTERS_NAMES[story]['perpetrators'], stopwords=STOPWORDS)\n","pp.pprint(perpetrator_neighbors_stop)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiOtszvkjZRz","colab_type":"code","colab":{}},"source":["# Plot top neighboring words\n","top_n = 10\n","\n","for character, freq_modes in perpetrator_neighbors_stop.items():\n","    for mode, freq_all in freq_modes.items():\n","        freq = get_frequent_items(freq_all, top_n)\n","        print(freq)\n","        if freq:\n","            barplot(list(freq.values()), list(freq.keys()))\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7kBPu0fK-6yr","colab_type":"text"},"source":["# EOF"]}]}